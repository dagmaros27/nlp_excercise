{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dagmaros27/AIMS_Notebooks/blob/main/CUDA_Practical_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CUDA Programming on NVIDIA GPUs, July 22-26, 2024**\n",
        "\n",
        "# **Practical 1**\n",
        "\n",
        "First of all, make sure the correct Runtime is being used, by clicking on the Runtime option at the top, then \"Change runtime type\", selecting an appropriate GPU such as the T4, then clicking Save.\n",
        "\n",
        "A Colab Pro or Pro+ account will allow you to use a more powerful GPU, but the freely available T4 is perfectly adequate for the practicals in this course. It has good single precision capabilities and corresponds to Compute Capability 7.5.\n",
        "\n",
        "To check that this has been done successfully, the first instruction below returns information on the version of the available NVIDIA compiler, and the second instruction returns information on the GPU which is available to you.  \n",
        "\n",
        "To \"execute\" each cell, click on the little triangle to the left of the instructions.  The ! tells Colab that these are system commands to be executed."
      ],
      "metadata": {
        "id": "i1JlUA_e44zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboEpcMD4xYA",
        "outputId": "4a959adb-3533-4160-b4d3-694db3affe0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnJ21Z177Tc2",
        "outputId": "651e2926-0ac6-4ec6-dca0-dbcfa1f19e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 14 08:07:56 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "The first step is to upload two header files from the course webpage."
      ],
      "metadata": {
        "id": "nlO6dHwW7gRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv1nyjTmTmr7",
        "outputId": "470edd5d-47b3-4f1e-a15f-2345e545e80f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-14 08:58:50--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:201::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27832 (27K) [text/x-chdr]\n",
            "Saving to: ‘helper_cuda.h’\n",
            "\n",
            "\rhelper_cuda.h         0%[                    ]       0  --.-KB/s               \rhelper_cuda.h       100%[===================>]  27.18K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2026-01-14 08:58:50 (2.33 MB/s) - ‘helper_cuda.h’ saved [27832/27832]\n",
            "\n",
            "--2026-01-14 08:58:50--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:201::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14875 (15K) [text/x-chdr]\n",
            "Saving to: ‘helper_string.h’\n",
            "\n",
            "helper_string.h     100%[===================>]  14.53K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2026-01-14 08:58:50 (1.26 MB/s) - ‘helper_string.h’ saved [14875/14875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "Next we create the file prac1a.cu by using the %%writefile instruction at the top of the code block.\n",
        "\n",
        "In doing this, we are following the helpful information provided here:\n",
        "https://colab.research.google.com/drive/1GJOfTp56OeQRdE4u2_S7pUNRcJb4ik9X?usp=sharing"
      ],
      "metadata": {
        "id": "FqvXt9br-gW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac1a.cu\n",
        "\n",
        "//\n",
        "// include files\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "//\n",
        "// kernel routine\n",
        "//\n",
        "\n",
        "__global__ void my_first_kernel(float *x)\n",
        "{\n",
        "  int tid = threadIdx.x + blockDim.x*blockIdx.x;\n",
        "\n",
        "  x[tid] = (float) threadIdx.x;\n",
        "}\n",
        "\n",
        "\n",
        "//\n",
        "// main code\n",
        "//\n",
        "\n",
        "int main(int argc, const char **argv)\n",
        "{\n",
        "  float *h_x, *d_x;\n",
        "  int   nblocks, nthreads, nsize, n;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // set number of blocks, and threads per block\n",
        "\n",
        "  nblocks  = 0;\n",
        "  nthreads = 8;\n",
        "  nsize    = nblocks*nthreads;\n",
        "\n",
        "  // allocate memory for array\n",
        "\n",
        "  h_x = (float *) malloc(nsize*sizeof(float));\n",
        "  cudaMalloc((void **) &d_x, nsize*sizeof(float));\n",
        "\n",
        "  // execute kernel\n",
        "\n",
        "  my_first_kernel<<<nblocks,nthreads>>>(d_x);\n",
        "\n",
        "  // copy back results and print them out\n",
        "\n",
        "  cudaMemcpy(h_x,d_x,nsize*sizeof(float),cudaMemcpyDefault);\n",
        "\n",
        "  for (n=0; n<nsize; n++) printf(\" n,  x  =  %d  %f \\n\",n,h_x[n]);\n",
        "\n",
        "  // free memory\n",
        "\n",
        "  cudaFree(d_x);\n",
        "  free(h_x);\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwQANS22i3Q",
        "outputId": "5c62738b-5b38-4bc8-f85c-3d5b46ab5b68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prac1a.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "We use the following instruction to compile prac1a.cu to create the executable output prac1a.  The other flags are as follows:\n",
        "\n",
        "-I. says to look in the current directory for header files\n",
        "\n",
        "-lineinfo helps with debugging if there's a run-time problem\n",
        "\n",
        "-arch=sm_70 says it is for GPUs of Compute Capability 7.0 or later\n",
        "\n",
        "--ptxas=-v gives us additional information such as how many registers are used\n",
        "\n",
        "--use_fast_math generates faster code which might sometimes be a little less accurate\n",
        "\n",
        "-lcudart links in the run-time CUDA library\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWTkuuk_arY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac1a.cu -o prac1a -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HObz_6vOa8P1",
        "outputId": "95a8da47-bffe-4c3d-a7e6-7ce25754afe6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z15my_first_kernelPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z15my_first_kernelPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 10 registers, 360 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Now we can execute the code.\n"
      ],
      "metadata": {
        "id": "Ku927eQ01g4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac1a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm0vvMosUm3C",
        "outputId": "f6ec84bf-15d2-44d3-8870-8fc650749e83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "We can now perform the same steps for the second code, prac1b.cu, which does lots of error-checking."
      ],
      "metadata": {
        "id": "yds03ug532rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac1b.cu\n",
        "\n",
        "\n",
        "//\n",
        "// include files\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "\n",
        "//\n",
        "// kernel routine\n",
        "//\n",
        "\n",
        "__global__ void my_first_kernel(float *x, float v1[], float v2[])\n",
        "{\n",
        "  int tid = threadIdx.x + blockDim.x*blockIdx.x;\n",
        "\n",
        "  float res = v1[tid] + v2[tid];\n",
        "\n",
        "  x[tid] = res;\n",
        "}\n",
        "\n",
        "\n",
        "//\n",
        "// main code\n",
        "//\n",
        "\n",
        "int main(int argc, const char **argv)\n",
        "{\n",
        "  float *h_x, *d_x;\n",
        "  int   nblocks, nthreads, nsize, n;\n",
        "\n",
        "  float *dv1, *dv2; // vectors for the device\n",
        "  float hv1[20], hv2[20]; // vectors for the host\n",
        "\n",
        "  int i;\n",
        "\n",
        "  for (i = 0; i < 20; i++) {\n",
        "        hv1[i] = (23.0*i*i) - (2.0/5.0*i) + 3;\n",
        "        hv2[i] = (11.0*i*i) + (5.0/7.0*i) - 120;\n",
        "  }\n",
        "\n",
        "//   for (i = 0; i < 20; i++) {\n",
        "//         printf(\"hv1 = %f, hv2 = %f for index = %d\\n\",\n",
        "//                hv1[i], hv2[i], i);\n",
        "//   }\n",
        "\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // set number of blocks, and threads per block\n",
        "\n",
        "  nblocks  = 2;\n",
        "  nthreads = 10;\n",
        "  nsize    = nblocks*nthreads;\n",
        "\n",
        "  // allocate memory for array\n",
        "\n",
        "  h_x = (float *) malloc(nsize*sizeof(float));\n",
        "  checkCudaErrors(cudaMalloc((void **) &d_x, nsize*sizeof(float)));\n",
        "  checkCudaErrors(cudaMalloc((void **) &dv1, nsize*sizeof(float)));\n",
        "  checkCudaErrors(cudaMalloc((void **) &dv2, nsize*sizeof(float)));\n",
        "\n",
        "  // transfer vectors\n",
        "  checkCudaErrors(cudaMemcpy(dv1, hv1, nsize*sizeof(float), cudaMemcpyHostToDevice));\n",
        "  checkCudaErrors(cudaMemcpy(dv2, hv2, nsize*sizeof(float), cudaMemcpyHostToDevice));\n",
        "  // execute kernel\n",
        "\n",
        "  my_first_kernel<<<nblocks,nthreads>>>(d_x, dv1, dv2);\n",
        "  getLastCudaError(\"my_first_kernel execution failed\\n\");\n",
        "\n",
        "  printf(\"this should be at the top, because of asyncronous \\n\");\n",
        "\n",
        "  // copy back results and print them out\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_x,d_x,nsize*sizeof(float),\n",
        "                 cudaMemcpyDefault) );\n",
        "\n",
        "  for (n=0; n<nsize; n++) printf(\" n,  x  =  %d  %f which equals = %f\\n\",n,h_x[n], hv1[n]+ hv2[n]);\n",
        "\n",
        "  // free memory\n",
        "\n",
        "  checkCudaErrors(cudaFree(d_x));\n",
        "  free(h_x);\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef7db4b-527e-473b-f848-9cb1f34f3ca1",
        "id": "vThsmRu7_7Zh"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prac1b.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac1b.cu -o prac1b -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcYvbrFvAEM-",
        "outputId": "c175fd08-dace-4f67-e0c7-c3cfc75d10ce"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z15my_first_kernelPfS_S_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z15my_first_kernelPfS_S_\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 12 registers, 376 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac1b"
      ],
      "metadata": {
        "id": "XFHWm4Dd3_hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ae7a14-3fed-4bea-b3c7-222fea8e8ddd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "this should be at the top, because of asyncronous \n",
            " n,  x  =  0  -117.000000 which equals = -117.000000\n",
            " n,  x  =  1  -82.685715 which equals = -82.685715\n",
            " n,  x  =  2  19.628571 which equals = 19.628571\n",
            " n,  x  =  3  189.942856 which equals = 189.942856\n",
            " n,  x  =  4  428.257141 which equals = 428.257141\n",
            " n,  x  =  5  734.571411 which equals = 734.571411\n",
            " n,  x  =  6  1108.885742 which equals = 1108.885742\n",
            " n,  x  =  7  1551.199951 which equals = 1551.199951\n",
            " n,  x  =  8  2061.514404 which equals = 2061.514404\n",
            " n,  x  =  9  2639.828613 which equals = 2639.828613\n",
            " n,  x  =  10  3286.142822 which equals = 3286.142822\n",
            " n,  x  =  11  4000.457275 which equals = 4000.457275\n",
            " n,  x  =  12  4782.771484 which equals = 4782.771484\n",
            " n,  x  =  13  5633.085938 which equals = 5633.085938\n",
            " n,  x  =  14  6551.399902 which equals = 6551.399902\n",
            " n,  x  =  15  7537.714355 which equals = 7537.714355\n",
            " n,  x  =  16  8592.028320 which equals = 8592.028320\n",
            " n,  x  =  17  9714.342773 which equals = 9714.342773\n",
            " n,  x  =  18  10904.657227 which equals = 10904.657227\n",
            " n,  x  =  19  12162.971680 which equals = 12162.971680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "By going back to the previous code blocks you can modify the codes to complete the Practical 1 exercises.  Alternatively you can copy a Code cell (on my system I do this by using the mouse right-click) and paste it (control-V on my system) to form a new Code cell -- this is best for the final exercise in which you are to write a new code to add two vectors.\n",
        "\n",
        "However, this copy of the notebook is read-only for everyone except the owner (me!) so you will need to make your own copy of the notebook by going to the File option at the top and then clicking on \"Save a copy in Drive\" which will make a copy of it in your Google Drive.  You are then the owner of the copy and can edit it freely.\n",
        "\n",
        "For students doing this as an assignment to be assessed, you should add your name to the title of the notebook (as in \"Practical 1 -- Mike Giles.ipynb\"), make it shared (see the Share option in the top-right corner) and provide the shared link as the submission mechanism."
      ],
      "metadata": {
        "id": "ncymVLmd4L82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This final piece of code terminates the runtime for this notebook so that you can switch to a new notebook without any problems -- you will get an error message if you try to keep two runtimes going at the same time with the free Colab account.\n",
        "\n",
        "It's particularly convenient if you are executing the whole notebook to check everything works correctly, using the \"Run all\" option in the Runtime tab."
      ],
      "metadata": {
        "id": "qwBJXY68f9W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "XFPuNsfygVaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}